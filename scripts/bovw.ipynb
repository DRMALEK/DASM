{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes all images and convert them to grayscale.\n",
    "# return a dictionary that holds all images category by category.\n",
    "def load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        category = []\n",
    "        path = folder + \"/\" + filename\n",
    "        for cat in os.listdir(path):\n",
    "            img = cv2.imread(path + \"/\" + cat,0)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            if img is not None:\n",
    "                category.append(img)\n",
    "        images[filename] = category\n",
    "    return images\n",
    "\n",
    "# Find the index of the closest central point to the each sift descriptor. \n",
    "# Takes 2 parameters the first one is a sift descriptor and the second one is the array of central points in k means\n",
    "# Returns the index of the closest central point.  \n",
    "def find_index(image, center):\n",
    "    count = 0\n",
    "    ind = 0\n",
    "    for i in range(len(center)):\n",
    "        if(i == 0):\n",
    "           count = distance.euclidean(image, center[i]) \n",
    "           #count = L1_dist(image, center[i])\n",
    "        else:\n",
    "            dist = distance.euclidean(image, center[i]) \n",
    "            #dist = L1_dist(image, center[i])\n",
    "            if(dist < count):\n",
    "                ind = i\n",
    "                count = dist\n",
    "    return ind\n",
    "\n",
    "# Creates descriptors using sift\n",
    "# Takes one parameter that is images dictionary\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def sift_features(images):\n",
    "    sift_vectors = {}\n",
    "    descriptor_list = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for key,value in images.items():\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "\n",
    "\n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        sift_vectors[key] = features\n",
    "    return [descriptor_list, sift_vectors]\n",
    "\n",
    "# Creates descriptors using sift\n",
    "# Takes one parameter that is images dictionary\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def orb_features(images):\n",
    "    orb_vectors = {}\n",
    "    descriptor_list = []\n",
    "    orb = cv2.ORB_create(nfeatures = 100)\n",
    "    for key,value in images.items():\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = orb.detectAndCompute(img,None)\n",
    "\n",
    "\n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "        orb_vectors[key] = features\n",
    "    return [descriptor_list, orb_vectors]\n",
    "\n",
    "# A k-means clustering algorithm who takes 2 parameter which is number\n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    return visual_words\n",
    "\n",
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class\n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class.\n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img:\n",
    "                ind = find_index(each_feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "\n",
    "# A k-means clustering algorithm who takes 2 parameter which is number\n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    return visual_words\n",
    "\n",
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class\n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class.\n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img:\n",
    "                ind = find_index(each_feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "\n",
    "# 1-NN algorithm. We use this for predict the class of test images.\n",
    "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
    "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "    preds = []\n",
    "    gts = []\n",
    "\n",
    "    for test_key, test_val in tests.items():\n",
    "        class_based[test_key] = [0, 0] # [correct, all]\n",
    "        for tst in test_val:\n",
    "            predict_start = 0\n",
    "            #print(test_key)\n",
    "            minimum = 0\n",
    "            key = \"a\" #predicted\n",
    "            for train_key, train_val in images.items():\n",
    "                for train in train_val:\n",
    "                    if(predict_start == 0):\n",
    "                        minimum = distance.euclidean(tst, train)\n",
    "                        #minimum = L1_dist(tst,train)\n",
    "                        key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = distance.euclidean(tst, train)\n",
    "                        #dist = L1_dist(tst,train)\n",
    "                        if(dist < minimum):\n",
    "                            minimum = dist\n",
    "                            key = train_key\n",
    "\n",
    "            if(test_key == key):\n",
    "                correct_predict += 1\n",
    "                class_based[test_key][0] += 1\n",
    "                preds.append(key)\n",
    "                gts.append(test_key)\n",
    "            else:\n",
    "                preds.append(key)\n",
    "                gts.append(test_key)\n",
    "    \n",
    "    \n",
    "            num_test += 1\n",
    "            class_based[test_key][1] += 1\n",
    "            #print(minimum)\n",
    "    return [num_test, correct_predict, class_based, preds, gts]\n",
    "\n",
    "# Calculates the average accuracy and class based accuracies.  \n",
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"\\nClass based accuracies: \\n\")\n",
    "    for key,value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(key + \" : %\" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load image is done!\n"
     ]
    }
   ],
   "source": [
    "images = load_images_from_folder('./train')  # take all images category by category\n",
    "test = load_images_from_folder(\"./test\") # take test images\n",
    "\n",
    "print(\"load image is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features extraion is done!\n"
     ]
    }
   ],
   "source": [
    "orbs = orb_features(images)\n",
    "\n",
    "# Takes the descriptor list which is unordered one\n",
    "descriptor_list = orbs[0]\n",
    "# Takes the orb features that is seperated class by class for train data\n",
    "all_bovw_feature = orbs[1]\n",
    "# Takes the orb features that is seperated class by class for test data\n",
    "test_bovw_feature = orb_features(test)[1]\n",
    "\n",
    "print(\"features extraion is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans is done!\n"
     ]
    }
   ],
   "source": [
    "# Takes the central points which is visual words\n",
    "visual_words = kmeans(9, descriptor_list)\n",
    "\n",
    "print(\"Kmeans is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building histograms is done!\n"
     ]
    }
   ],
   "source": [
    "# Creates histograms for train data\n",
    "bovw_train = image_class(all_bovw_feature, visual_words)\n",
    "# Creates histograms for test data\n",
    "bovw_test = image_class(test_bovw_feature, visual_words)\n",
    "\n",
    "print(\"Building histograms is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the knn function\n",
    "results_bowl = knn(bovw_train, bovw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: %84.69055374592834\n",
      "\n",
      "Class based accuracies: \n",
      "\n",
      "road_mid\n",
      " : %89.65517241379311\n",
      "road_low\n",
      " : %84.44444444444444\n",
      "building_high\n",
      " : %84.0909090909091\n",
      "building_low\n",
      " : %84.61538461538461\n",
      "bridge_mid\n",
      " : %78.57142857142857\n",
      "road_high\n",
      " : %84.61538461538461\n",
      "bridge_high\n",
      " : %74.19354838709677\n",
      "building_mid\n",
      " : %89.47368421052632\n",
      "bridge_low\n",
      " : %89.36170212765957\n"
     ]
    }
   ],
   "source": [
    "# Calculates the accuracies and write the results to the console.       \n",
    "accuracy(results_bowl) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
